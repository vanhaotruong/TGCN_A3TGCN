{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-5Jpgg49wzb",
    "outputId": "ec14c399-bd0d-4523-cdbc-4084ddfbfcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.0+cu126\n",
      "Uninstalling torch-2.9.0+cu126:\n",
      "  Successfully uninstalled torch-2.9.0+cu126\n",
      "Found existing installation: torchvision 0.24.0+cu126\n",
      "Uninstalling torchvision-0.24.0+cu126:\n",
      "  Successfully uninstalled torchvision-0.24.0+cu126\n",
      "Found existing installation: torchaudio 2.9.0+cu126\n",
      "Uninstalling torchaudio-2.9.0+cu126:\n",
      "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
      "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric-temporal as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m816.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.20.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
      "Installing collected packages: torch-scatter, torch-sparse\n",
      "Successfully installed torch-scatter-2.1.2+pt25cu124 torch-sparse-0.6.18+pt25cu124\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch-geometric-temporal\n",
      "  Downloading torch_geometric_temporal-0.56.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.5.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
      "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (25.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (3.0.12)\n",
      "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (0.6.18+pt25cu124)\n",
      "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (2.1.2+pt25cu124)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (3.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse->torch-geometric-temporal) (1.16.3)\n",
      "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_geometric_temporal-0.56.2-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightning-utilities, torch-geometric, torchmetrics, torch-geometric-temporal, pytorch_lightning\n",
      "Successfully installed lightning-utilities-0.15.2 pytorch_lightning-2.6.0 torch-geometric-2.7.0 torch-geometric-temporal-0.56.2 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "# 1. Gỡ bỏ phiên bản quá mới hiện tại\n",
    "!pip uninstall torch torchvision torchaudio torch-scatter torch-sparse torch-geometric torch-geometric-temporal -y\n",
    "\n",
    "# 2. Cài đặt PyTorch 2.5.1 (Bản ổn định) + CUDA 12.4\n",
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# 3. Cài đặt các thư viện vệ tinh (Scatter/Sparse) dành RIÊNG cho bản 2.5.1\n",
    "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
    "\n",
    "# 4. Cài thư viện chính\n",
    "!pip install pytorch_lightning torch-geometric torch-geometric-temporal\n",
    "\n",
    "# # 5. Runtime > Restart session\n",
    "# # 6 Ignore this !pip section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 6172,
     "status": "error",
     "timestamp": 1768380494093,
     "user": {
      "displayName": "van hao truong",
      "userId": "08998182992862504611"
     },
     "user_tz": -420
    },
    "id": "xDk5XgSY3-_w",
    "outputId": "4b24502f-92da-42d7-8a99-05db6574f795"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yrrEyokS4NK9"
   },
   "outputs": [],
   "source": [
    "def load_tgcn_data(data_dir='data'):\n",
    "    print(\"Loading interactions...\")\n",
    "    # Load and process interaction data\n",
    "    # Only using book_interaction.csv\n",
    "    file_path = os.path.join(data_dir, 'book_interaction.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    df_inter = pd.read_csv(file_path)\n",
    "    # Clean column names (strip type suffix if present, e.g. user_id:token -> user_id)\n",
    "    df_inter.columns = [c.split(':')[0] for c in df_inter.columns]\n",
    "\n",
    "    # Ensure timestamp is datetime\n",
    "    df_inter['timestamp'] = pd.to_datetime(df_inter['timestamp'])\n",
    "\n",
    "    print(\"Mapping IDs...\")\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "\n",
    "    # Encode Users and Items\n",
    "    df_inter['user_idx'] = user_encoder.fit_transform(df_inter['user_id'].astype(str))\n",
    "    df_inter['item_idx'] = item_encoder.fit_transform(df_inter['item_id'].astype(str))\n",
    "\n",
    "    num_users = len(user_encoder.classes_)\n",
    "    num_items = len(item_encoder.classes_)\n",
    "\n",
    "    print(f\"Total Users: {num_users}, Total Items: {num_items}\")\n",
    "\n",
    "    print(\"Creating temporal snapshots...\")\n",
    "    df_inter['month'] = df_inter['timestamp'].dt.to_period('M')\n",
    "    # Sort by month to ensure temporal order\n",
    "    months = sorted(df_inter['month'].unique())\n",
    "\n",
    "    # 1. Determine Training Split (70%) to build the static graph\n",
    "    train_len_months = int(len(months) * 0.7)\n",
    "    train_months = months[:train_len_months]\n",
    "\n",
    "    # 2. Get all interactions in the training set\n",
    "    df_train = df_inter[df_inter['month'].isin(train_months)]\n",
    "\n",
    "    # 3. Build Static Edge Index from Train Set\n",
    "    train_u_idx = df_train['user_idx'].values\n",
    "    train_i_idx = df_train['item_idx'].values\n",
    "\n",
    "    train_u_node_idx = torch.tensor(train_u_idx, dtype=torch.long)\n",
    "    train_i_node_idx = torch.tensor(train_i_idx + num_users, dtype=torch.long)\n",
    "\n",
    "    # Create undirected graph from unique training interactions\n",
    "    # Note: torch.unique might be needed if multiple interactions exist, but edge_index usually works fine with multis.\n",
    "    # We'll use the raw list; duplicates increase weight in message passing or are redundant.\n",
    "    # For efficiency and cleanliness, let's keep unique edges.\n",
    "    train_edges_df = df_train[['user_idx', 'item_idx']].drop_duplicates()\n",
    "    unique_u_idx = torch.tensor(train_edges_df['user_idx'].values, dtype=torch.long)\n",
    "    unique_i_idx = torch.tensor(train_edges_df['item_idx'].values + num_users, dtype=torch.long)\n",
    "\n",
    "    train_edge_index = torch.stack([\n",
    "        torch.cat([unique_u_idx, unique_i_idx]),\n",
    "        torch.cat([unique_i_idx, unique_u_idx])\n",
    "    ], dim=0)\n",
    "\n",
    "    print(f\"Static Training Graph created with {train_edges_df.shape[0]} edges.\")\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for m in months:\n",
    "        snapshot_df = df_inter[df_inter['month'] == m]\n",
    "        if snapshot_df.empty:\n",
    "            continue\n",
    "\n",
    "        u_idx_raw = snapshot_df['user_idx'].values\n",
    "        i_idx_raw = snapshot_df['item_idx'].values\n",
    "\n",
    "        # Node indices for validataion/testing targets\n",
    "        u_node_idx = torch.tensor(u_idx_raw, dtype=torch.long)\n",
    "        i_node_idx = torch.tensor(i_idx_raw + num_users, dtype=torch.long)\n",
    "\n",
    "        # Use the STATIC train_edge_index for Graph Structure\n",
    "        dataset.append({\n",
    "            'edge_index': train_edge_index,\n",
    "            'y': torch.ones(len(snapshot_df), dtype=torch.float), # All interactions are positive (likes)\n",
    "            'target_u': u_node_idx,\n",
    "            'target_i': i_node_idx\n",
    "        })\n",
    "\n",
    "    print(f\"Loaded {len(dataset)} snapshots.\")\n",
    "\n",
    "    # Split into Train (First 70%) and Remainder (30%)\n",
    "    # Requirement: First 70% for training (temporal). Remaining 30% randomly split into Val and Test.\n",
    "    total_len = len(dataset)\n",
    "    train_len = int(total_len * 0.7)\n",
    "\n",
    "    train_dataset = dataset[:train_len]\n",
    "    remainder_dataset = dataset[train_len:]\n",
    "\n",
    "    # Shuffle the remainder to randomize validation/test split\n",
    "    import random\n",
    "    random.shuffle(remainder_dataset)\n",
    "\n",
    "    # Allocate roughly 10% of total (1/3 of remainder) to val, and 20% (2/3 of remainder) to test\n",
    "    val_len = int(total_len * 0.1)\n",
    "\n",
    "    val_dataset = remainder_dataset[:val_len]\n",
    "    test_dataset = remainder_dataset[val_len:]\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8-L86-kxBGia"
   },
   "outputs": [],
   "source": [
    "class TGCNRecommender(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, lr=0.01, interaction_batch_size=1024):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Important: We use manual optimization to handle mini-batches of interactions\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Learnable Node Embeddings\n",
    "        self.node_emb = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_emb.weight)\n",
    "\n",
    "        # T-GCN Layer\n",
    "        self.tgcn = TGCN(in_channels=embedding_dim, out_channels=embedding_dim)\n",
    "\n",
    "        # Predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.h = None\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        self.h = None\n",
    "\n",
    "    def forward(self, edge_index, target_u, target_i, h):\n",
    "        # 1. Get current node embeddings\n",
    "        x = self.node_emb.weight\n",
    "\n",
    "        # 2. Update Embeddings with T-GCN\n",
    "        # h_new shape: [num_nodes, embedding_dim]\n",
    "        h_new = self.tgcn(x, edge_index, None, h)\n",
    "\n",
    "        # 3. Lookup Embeddings for target pairs\n",
    "        u_emb = h_new[target_u]\n",
    "        i_emb = h_new[target_i]\n",
    "\n",
    "        # 4. Predict Rating\n",
    "        combined = torch.cat([u_emb, i_emb], dim=1)\n",
    "        out = self.predictor(combined)\n",
    "\n",
    "        return out, h_new\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "\n",
    "        # Unpack snapshot data\n",
    "        edge_index, y = batch['edge_index'], batch['y']\n",
    "        target_u, target_i = batch['target_u'], batch['target_i']\n",
    "\n",
    "        # 1. Update Hidden State (TGCN) - ONCE per snapshot\n",
    "        if self.h is None:\n",
    "             self.h = torch.zeros(self.num_nodes, self.embedding_dim, device=self.device)\n",
    "        else:\n",
    "             self.h = self.h.to(self.device).detach()\n",
    "\n",
    "        # We run TGCN on the full graph to get updated embeddings for this timestamp\n",
    "        x = self.node_emb.weight\n",
    "        h_new = self.tgcn(x, edge_index, None, self.h)\n",
    "\n",
    "        # 2. Mini-batch Training on Interactions\n",
    "        # Split the interactions (users, items, ratings) into smaller chunks\n",
    "        num_interactions = len(target_u)\n",
    "        perm_indices = torch.randperm(num_interactions, device=self.device)\n",
    "\n",
    "        batch_size = self.hparams.interaction_batch_size\n",
    "        epoch_losses = []\n",
    "\n",
    "        for start_idx in range(0, num_interactions, batch_size):\n",
    "            idx = perm_indices[start_idx : start_idx + batch_size]\n",
    "\n",
    "            batch_u = target_u[idx]\n",
    "            batch_i = target_i[idx]\n",
    "            batch_y = y[idx]\n",
    "\n",
    "            # Predict using the snapshot embeddings\n",
    "            u_emb = h_new[batch_u]\n",
    "            i_emb = h_new[batch_i]\n",
    "\n",
    "            combined = torch.cat([u_emb, i_emb], dim=1)\n",
    "            y_hat = self.predictor(combined).view(-1)\n",
    "\n",
    "            loss = F.mse_loss(y_hat, batch_y)\n",
    "\n",
    "            # Manual Optimization Step\n",
    "            opt.zero_grad()\n",
    "            self.manual_backward(loss)\n",
    "            opt.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        # Update hidden state for next snapshot (recurrence)\n",
    "        self.h = h_new.detach()\n",
    "\n",
    "        mean_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0\n",
    "        self.log(\"train_loss\", mean_loss, prog_bar=True)\n",
    "\n",
    "        # Return nothing because we did manual optimization\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate_step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._evaluate_step(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _evaluate_step(self, batch, batch_idx, stage):\n",
    "        edge_index, y = batch['edge_index'], batch['y']\n",
    "        target_u, target_i = batch['target_u'], batch['target_i']\n",
    "\n",
    "        if self.h is None:\n",
    "             self.h = torch.zeros(self.num_nodes, self.embedding_dim, device=self.device)\n",
    "        else:\n",
    "             self.h = self.h.to(self.device).detach()\n",
    "\n",
    "        # Forward pass (Full Batch inference for embeddings is usually fine,\n",
    "        # but we batch the scoring to save memory)\n",
    "        x = self.node_emb.weight\n",
    "        h_new = self.tgcn(x, edge_index, None, self.h)\n",
    "        self.h = h_new.detach()\n",
    "\n",
    "        # Evaluation in chunks\n",
    "        batch_size = self.hparams.interaction_batch_size\n",
    "        num_interactions = len(target_u)\n",
    "\n",
    "        total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
    "\n",
    "        for start_idx in range(0, num_interactions, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_interactions)\n",
    "            batch_u = target_u[start_idx:end_idx]\n",
    "            batch_i = target_i[start_idx:end_idx]\n",
    "\n",
    "            # Positive Predictions\n",
    "            u_emb = h_new[batch_u]\n",
    "            i_emb = h_new[batch_i]\n",
    "            pos_preds = self.predictor(torch.cat([u_emb, i_emb], dim=1)).view(-1)\n",
    "            pos_probs = torch.sigmoid(pos_preds)\n",
    "\n",
    "            # Negative Sampling (1:1)\n",
    "            # We generate negatives on the fly for evaluation\n",
    "            neg_i = torch.randint(\n",
    "                self.hparams.num_users,\n",
    "                self.hparams.num_users + self.hparams.num_items,\n",
    "                (len(batch_u),),\n",
    "                device=self.device\n",
    "            )\n",
    "            neg_i_emb = h_new[neg_i]\n",
    "            neg_preds = self.predictor(torch.cat([u_emb, neg_i_emb], dim=1)).view(-1)\n",
    "            neg_probs = torch.sigmoid(neg_preds)\n",
    "\n",
    "            # Metrics\n",
    "            all_probs = torch.cat([pos_probs, neg_probs])\n",
    "            all_labels = torch.cat([torch.ones_like(pos_probs), torch.zeros_like(neg_probs)])\n",
    "            preds = (all_probs > 0.5).float()\n",
    "\n",
    "            total_tp += ((preds == 1) & (all_labels == 1)).sum().item()\n",
    "            total_fp += ((preds == 1) & (all_labels == 0)).sum().item()\n",
    "            total_fn += ((preds == 0) & (all_labels == 1)).sum().item()\n",
    "            total_tn += ((preds == 0) & (all_labels == 0)).sum().item()\n",
    "\n",
    "        precision = total_tp / (total_tp + total_fp + 1e-8)\n",
    "        recall = total_tp / (total_tp + total_fn + 1e-8)\n",
    "        accuracy = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn + 1e-8)\n",
    "\n",
    "        self.log_dict({\n",
    "            f\"{stage}_precision\": precision,\n",
    "            f\"{stage}_recall\": recall,\n",
    "            f\"{stage}_accuracy\": accuracy\n",
    "        }, prog_bar=True)\n",
    "\n",
    "        return precision\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aRuOnaapBK81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interactions...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: home/hp/GoogleDrive/Computer Science Master/01 Luan Van/data/book_interaction.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1840507148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Reload data to ensure clean state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tgcn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"home/hp/GoogleDrive/Computer Science Master/01 Luan Van/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Model Init with Interaction Batch Size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-756336615.py\u001b[0m in \u001b[0;36mload_tgcn_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'book_interaction.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File not found: {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_inter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File not found: home/hp/GoogleDrive/Computer Science Master/01 Luan Van/data/book_interaction.csv"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Reload data to ensure clean state\n",
    "    train_dataset, val_dataset, test_dataset, num_users, num_items = load_tgcn_data(\"home/hp/GoogleDrive/Computer Science Master/01 Luan Van/data\")\n",
    "\n",
    "    # Model Init with Interaction Batch Size\n",
    "    embedding_dim = 64\n",
    "    # We set interaction_batch_size to process ratings in chunks\n",
    "    model = TGCNRecommender(\n",
    "        num_users=num_users,\n",
    "        num_items=num_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        interaction_batch_size=1024 # Adjust this based on GPU memory\n",
    "    )\n",
    "\n",
    "    # DataLoaders - Keep batch_size=1 to load one temporal snapshot at a time\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0], shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=lambda x: x[0], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0], shuffle=False)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        # log_every_n_steps=1 might be too frequent for inner loops, but okay here\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    print(\"Starting Training...\")\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    print(\"Training Complete!\")\n",
    "\n",
    "    print(\"Starting Testing...\")\n",
    "    trainer.test(model, test_loader)\n",
    "    print(\"Testing Complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqa2xQZFwDaTImHhVca8F7",
   "gpuType": "T4",
   "mount_file_id": "1xEeIB3zDaFVJwvNavB_5aFrzl6IqQUC5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
