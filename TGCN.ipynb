{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-5Jpgg49wzb",
    "outputId": "ec14c399-bd0d-4523-cdbc-4084ddfbfcfb"
   },
   "outputs": [],
   "source": [
    "# # 1. G·ª° b·ªè phi√™n b·∫£n qu√° m·ªõi hi·ªán t·∫°i\n",
    "# !pip uninstall torch torchvision torchaudio torch-scatter torch-sparse torch-geometric torch-geometric-temporal -y\n",
    "\n",
    "# # 2. C√†i ƒë·∫∑t PyTorch 2.5.1 (B·∫£n ·ªïn ƒë·ªãnh) + CUDA 12.4\n",
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# # 3. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán v·ªá tinh (Scatter/Sparse) d√†nh RI√äNG cho b·∫£n 2.5.1\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
    "\n",
    "# # 4. C√†i th∆∞ vi·ªán ch√≠nh\n",
    "# !pip install pytorch_lightning torch-geometric torch-geometric-temporal\n",
    "\n",
    "# # # 5. Runtime > Restart session\n",
    "# # # 6 Ignore this !pip section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 6172,
     "status": "error",
     "timestamp": 1768380494093,
     "user": {
      "displayName": "van hao truong",
      "userId": "08998182992862504611"
     },
     "user_tz": -420
    },
    "id": "xDk5XgSY3-_w",
    "outputId": "4b24502f-92da-42d7-8a99-05db6574f795"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN, EvolveGCNH\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAwareBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    K√≠ch ho·∫°t vi·ªác l·∫•y m·∫´u theo t·ª´ng b∆∞·ªõc th·ªùi gian (Time Step).\n",
    "    ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c m·∫´u trong m·ªôt batch ƒë·ªÅu thu·ªôc c√πng m·ªôt th·ªùi ƒëi·ªÉm 'time_idx'.\n",
    "    ƒêi·ªÅu n√†y c·ª±c k·ª≥ quan tr·ªçng cho T-GCN ƒë·ªÉ x·ª≠ l√Ω ƒë√∫ng c·ª≠a s·ªï ƒë·ªì th·ªã (edge_index_window).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source, batch_size, shuffle=True):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # data_source l√† TensorDataset(users, items, time_indices)\n",
    "        # Ch√∫ng ta c·∫ßn gom nh√≥m index thay theo time_idx\n",
    "        self.time_indices = data_source.tensors[2].numpy()\n",
    "        \n",
    "        # T·∫°o dictionary: time_idx -> list of dataset_indices\n",
    "        self.time_groups = defaultdict(list)\n",
    "        for idx, t in enumerate(self.time_indices):\n",
    "            self.time_groups[t].append(idx)\n",
    "            \n",
    "        self.time_keys = sorted(list(self.time_groups.keys()))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Lu√¥n gi·ªØ th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn ƒë·ªÉ m√¥ h√¨nh h·ªçc theo di·ªÖn ti·∫øn l·ªãch s·ª≠\n",
    "        # (Kh√¥ng shuffle keys n·ªØa)\n",
    "        keys = self.time_keys[:] \n",
    "            \n",
    "        for t in keys:\n",
    "            indices = self.time_groups[t][:]\n",
    "            \n",
    "            # Ch·ªâ x√°o tr·ªôn d·ªØ li·ªáu B√äN TRONG m·ªôt th√°ng\n",
    "            # ƒê·ªÉ c√°c batch trong c√πng 1 th√°ng c√≥ s·ª± ng·∫´u nhi√™n\n",
    "            if self.shuffle:\n",
    "                random.shuffle(indices)\n",
    "            \n",
    "            # T·∫°o c√°c batch t·ª´ indices c·ªßa th·ªùi ƒëi·ªÉm t\n",
    "            for i in range(0, len(indices), self.batch_size):\n",
    "                yield indices[i : i + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        # T·ªïng s·ªë batch\n",
    "        count = 0\n",
    "        for t in self.time_keys:\n",
    "            indices = self.time_groups[t]\n",
    "            count += (len(indices) + self.batch_size - 1) // self.batch_size\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, interaction_file, min_interactions= 100, batch_size=1024, train_size=0.7, val_size=0.15, test_size=0.15, built_dataset=None):\n",
    "        super().__init__()\n",
    "        self.interaction_file = interaction_file\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self.min_interactions = min_interactions\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # --- 1. Load & Preprocess ---\n",
    "        df = pd.read_csv(self.interaction_file)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "        df['month'] = df['timestamp'].dt.to_period('M')\n",
    "\n",
    "        # ƒê·∫øm s·ªë d√≤ng m·ªói th√°ng\n",
    "        month_counts = df['month'].value_counts()\n",
    "        valid_months = month_counts[month_counts >= self.min_interactions].index\n",
    "        \n",
    "        # Ch·ªâ gi·ªØ l·∫°i th√°ng h·ª£p l·ªá\n",
    "        df = df[df['month'].isin(valid_months)].copy()\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"D·ªØ li·ªáu sau khi l·ªçc b·ªã r·ªóng! H√£y gi·∫£m ng∆∞·ª°ng MIN_INTERACTIONS.\")\n",
    "            \n",
    "        print(f\"Removed months with < {self.min_interactions} interactions. Remaining months: {len(valid_months)}\")\n",
    "\n",
    "        # Mapping ID\n",
    "        unique_users = df['user_id'].unique()\n",
    "        unique_items = df['item_id'].unique()\n",
    "        \n",
    "        self.num_users = len(unique_users)\n",
    "        self.num_items = len(unique_items)\n",
    "        self.user_to_idx = {u: idx for idx, u in enumerate(unique_users)}\n",
    "        self.item_to_idx = {i: idx for idx, i in enumerate(unique_items)}\n",
    "\n",
    "        df['user_idx'] = df['user_id'].map(self.user_to_idx)\n",
    "        df['item_idx'] = df['item_id'].map(self.item_to_idx)\n",
    "\n",
    "        # T·∫°o Time Index (0, 1, 2, ...) cho c√°c th√°ng\n",
    "        valid_months_sorted = sorted(valid_months)\n",
    "\n",
    "        month_to_idx = {m: i for i, m in enumerate(valid_months_sorted)}\n",
    "        df['time_idx'] = df['month'].map(month_to_idx)\n",
    "        \n",
    "        self.num_time_steps = len(valid_months_sorted)\n",
    "\n",
    "        # --- 2. Temporal Split ---\n",
    "        train_end = int(self.num_time_steps * self.train_size)\n",
    "        val_end = train_end + int(self.num_time_steps * self.val_size)\n",
    "        \n",
    "        train_months = valid_months_sorted[:train_end]\n",
    "        val_months = valid_months_sorted[train_end:val_end]\n",
    "        test_months = valid_months_sorted[val_end:]\n",
    "        \n",
    "        # L·ªçc Time Index t∆∞∆°ng ·ª©ng\n",
    "        self.train_df = df[df['month'].isin(train_months)].sort_values('timestamp')\n",
    "        self.val_df = df[df['month'].isin(val_months)].sort_values('timestamp')\n",
    "        self.test_df = df[df['month'].isin(test_months)].sort_values('timestamp')\n",
    "\n",
    "        # --- 3. Build Graph cho TO√ÄN B·ªò th·ªùi gian ---\n",
    "        self.edge_index_all = [None] * self.num_time_steps\n",
    "        \n",
    "        for month, group in df.groupby('month'):\n",
    "            t_idx = month_to_idx[month]\n",
    "            \n",
    "            src = torch.tensor(group['user_idx'].values, dtype=torch.long)\n",
    "            dst = torch.tensor(group['item_idx'].values, dtype=torch.long) + self.num_users\n",
    "            \n",
    "            # Undirected\n",
    "            edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n",
    "            self.edge_index_all[t_idx] = edge_index\n",
    "\n",
    "        # Fill c√°c th√°ng b·ªã thi·∫øu\n",
    "        for t in range(self.num_time_steps):\n",
    "            if self.edge_index_all[t] is None:\n",
    "                self.edge_index_all[t] = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        # --- 4. User History ---\n",
    "        self.train_user_pos_items = self._build_user_history(self.train_df)\n",
    "        self.val_user_pos_items = self._build_user_history(self.val_df)\n",
    "        self.test_user_pos_items = self._build_user_history(self.test_df)\n",
    "\n",
    "    def _build_user_history(self, df_subset):\n",
    "        user_pos_items = defaultdict(set)\n",
    "        for u, i in zip(df_subset['user_idx'], df_subset['item_idx']):\n",
    "            user_pos_items[u].add(i)\n",
    "        return user_pos_items\n",
    "\n",
    "    def _create_dataset(self, df_subset):\n",
    "        if len(df_subset) == 0:\n",
    "            return TensorDataset(torch.empty(0), torch.empty(0), torch.empty(0))\n",
    "            \n",
    "        users = torch.tensor(df_subset['user_idx'].values, dtype=torch.long)\n",
    "        items = torch.tensor(df_subset['item_idx'].values, dtype=torch.long)\n",
    "        times = torch.tensor(df_subset['time_idx'].values, dtype=torch.long)\n",
    "        \n",
    "        return TensorDataset(users, items, times)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self._create_dataset(self.train_df)\n",
    "        batch_sampler = TimeAwareBatchSampler(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        return DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self._create_dataset(self.val_df)\n",
    "        batch_sampler = TimeAwareBatchSampler(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self._create_dataset(self.test_df)\n",
    "        batch_sampler = TimeAwareBatchSampler(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return DataLoader(dataset, batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGCNRecommender(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, sequence_length, embedding_dim, lr, dropout=0.2, weight_decay=1e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.seq_len = sequence_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lr = lr\n",
    "        self.dropout_rate = dropout\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.node_emb = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_emb.weight)\n",
    "        \n",
    "        self.tgcn = TGCN(in_channels=embedding_dim, out_channels=embedding_dim) \n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.edge_index_all = self.trainer.datamodule.edge_index_all\n",
    "        self.train_user_pos_items = self.trainer.datamodule.train_user_pos_items\n",
    "        self.val_user_pos_items = self.trainer.datamodule.val_user_pos_items\n",
    "        self.test_user_pos_items = self.trainer.datamodule.test_user_pos_items\n",
    "        \n",
    "    @staticmethod\n",
    "    def hit_at_k(pred_items, true_items, k):\n",
    "        hits = 0\n",
    "        for pred, true in zip(pred_items, true_items):\n",
    "            if len(set(pred[:k]) & set(true)) > 0:\n",
    "                hits += 1\n",
    "        return hits / len(true_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def ndcg_at_k(pred_items, true_items, k):\n",
    "        ndcg = 0.0\n",
    "        for pred, true in zip(pred_items, true_items):\n",
    "            gains = []\n",
    "            for idx, item in enumerate(pred[:k]):\n",
    "                gains.append(1 if item in true else 0)\n",
    "            ideal_gains = [1] * min(len(true), k)\n",
    "            dcg = sum(g / math.log2(i+2) for i, g in enumerate(gains))\n",
    "            idcg = sum(g / math.log2(i+2) for i, g in enumerate(ideal_gains))\n",
    "            ndcg += dcg / idcg if idcg > 0 else 0\n",
    "        return ndcg / len(true_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def recall_at_k(pred_items, true_items, k):\n",
    "        recall = 0.0\n",
    "        for pred, true in zip(pred_items, true_items):\n",
    "            recall += len(set(pred[:k]) & set(true)) / len(true)\n",
    "        return recall / len(true_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def precision_at_k(pred_items, true_items, k):\n",
    "        precision = 0.0\n",
    "        for pred, true in zip(pred_items, true_items):\n",
    "            precision += len(set(pred[:k]) & set(true)) / k\n",
    "        return precision / len(true_items)\n",
    "\n",
    "    def forward(self, time_idx):\n",
    "        if time_idx == 0:\n",
    "            return self.node_emb.weight\n",
    "        \n",
    "        start = max(0, time_idx - self.seq_len)\n",
    "        window_edges = self.edge_index_all[start : time_idx] \n",
    "        \n",
    "        x = self.node_emb.weight\n",
    "        # Apply Dropout to input features\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        h = torch.zeros(self.num_nodes, self.embedding_dim).to(x.device)\n",
    "        \n",
    "        for edge_index in window_edges:\n",
    "            edge_index = edge_index.to(x.device)          \n",
    "            h = self.tgcn(X=x, edge_index=edge_index, H=h) \n",
    "\n",
    "        return h\n",
    "\n",
    "    def compute_loss(self, batch, user_embs, item_embs):\n",
    "        user_ids, pos_item_ids, time_indices = batch\n",
    "\n",
    "        # Get embeddings\n",
    "        user_emb = user_embs[user_ids]\n",
    "        pos_emb = item_embs[pos_item_ids]\n",
    "\n",
    "        # Compute positive scores\n",
    "        pos_scores = torch.exp(-torch.abs(user_emb - pos_emb).sum(dim=1))\n",
    "\n",
    "        ####################### Hard negative Sampling #######################\n",
    "        distances = torch.cdist(user_emb, item_embs, p=1)\n",
    "        scores = torch.exp(-distances)\n",
    "\n",
    "        ######## Mask all pos_item_ids of the user in train_dataset ########\n",
    "        ### Basically, the  model should only see the information in the train_dataset.\n",
    "        ### Therefore, only mask the pos_item_ids of the user in train_dataset\n",
    "        ### All cell (user, item) in val_dataset should be treated as blank hence don't mask the val_dataset\n",
    "\n",
    "        for i, u in enumerate(user_ids.tolist()):\n",
    "            pos_item_ids = [item for item in self.train_user_pos_items[u]]\n",
    "            scores[i, pos_item_ids] = float('-inf')\n",
    "        ######## Mask all pos_item_ids of the user in train_dataset ########\n",
    "\n",
    "        k = 10 # Select top-K most negatives for each user\n",
    "        neg_item_ids = torch.topk(scores, k=k, dim=1).indices\n",
    "\n",
    "        # Get embeddings for these negatives\n",
    "        neg_emb = item_embs[neg_item_ids]\n",
    "\n",
    "        neg_scores = torch.exp(-torch.abs(user_emb.unsqueeze(1) - neg_emb).sum(dim=2))\n",
    "        neg_scores = neg_scores.mean(dim=1)\n",
    "        ####################### Hard negative Sampling #######################\n",
    "\n",
    "\n",
    "        ####################### Compute Loss #######################\n",
    "        scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "        labels = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)], dim=0)\n",
    "\n",
    "        loss = F.binary_cross_entropy(scores, labels)\n",
    "        ####################### Compute Loss #######################\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_ids, item_ids, time_indices = batch\n",
    "        current_t = time_indices[0].item()\n",
    "        \n",
    "        node_embs = self(current_t) \n",
    "        user_embs = node_embs[:self.num_users]\n",
    "        item_embs = node_embs[self.num_users:]\n",
    "\n",
    "        loss = self.compute_loss(batch, user_embs, item_embs)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_ids, item_ids, time_indices = batch\n",
    "\n",
    "        current_t = time_indices[0].item()\n",
    "        \n",
    "        node_embs = self(current_t) \n",
    "\n",
    "        user_embs = node_embs[:self.num_users]\n",
    "        item_embs = node_embs[self.num_users:]\n",
    "\n",
    "        batch_user_emb = user_embs[user_ids]\n",
    "\n",
    "        distances = torch.cdist(batch_user_emb, item_embs, p=1)\n",
    "        scores = torch.exp(-distances)  # it is the score between the ith user in batch_size and ALL items\n",
    "\n",
    "        ########## Mask those user-item pair that already in training set so that it won't suggest again\n",
    "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
    "        for i, u in enumerate(user_ids.tolist()):\n",
    "            trained_items = [item for item in self.train_user_pos_items[u]]\n",
    "            mask[i, trained_items] = True\n",
    "\n",
    "        scores = scores.masked_fill(mask, float('-inf'))    #### Make them to -inf so that TopK won't pick again\n",
    "        ########## Mask those user-item pair that already in training set so that it won't suggest again\n",
    "\n",
    "        #################### Calculate metrics\n",
    "        # k_values = [5, 10, 15, 20]  # Example: you can add more values as needed\n",
    "        k_values = [10]\n",
    "\n",
    "        for k in k_values:\n",
    "            # Get top-k items for this k\n",
    "            topk_items = torch.topk(scores, k=k, dim=1).indices.tolist() # (1024, K=5)\n",
    "\n",
    "            true_items = []  # each user may have multiple positive items\n",
    "            for u in user_ids.tolist():\n",
    "                adjusted_val_items = [item - self.num_users for item in self.val_user_pos_items[u]]\n",
    "                true_items.append(adjusted_val_items)\n",
    "\n",
    "            # Compute metrics for this k\n",
    "            hit = self.hit_at_k(topk_items, true_items, k)\n",
    "            ndcg = self.ndcg_at_k(topk_items, true_items, k)\n",
    "            recall = self.recall_at_k(topk_items, true_items, k)\n",
    "            precision = self.precision_at_k(topk_items, true_items, k)\n",
    "\n",
    "            # Log metrics dynamically\n",
    "            self.log(f\"val_hit@{k:02d}\", hit, prog_bar=True)\n",
    "            self.log(f\"val_recall@{k:02d}\", recall, prog_bar=True)\n",
    "            self.log(f\"val_precision@{k:02d}\", precision, prog_bar=True)\n",
    "            self.log(f\"val_ndcg@{k:02d}\", ndcg, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, recall_10, precision_10 = self._common_step(batch, evaluate=True, k=10)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_recall_10\", recall_10, prog_bar=True)\n",
    "        self.log(\"test_precision_10\", precision_10, prog_bar=True)\n",
    "        return loss\n",
    "        \n",
    "    def _common_step(self, batch, evaluate=False, k=10):\n",
    "        user_ids, item_ids, time_indices = batch\n",
    "        current_t = time_indices[0].item()\n",
    "        \n",
    "        node_embs = self(current_t) \n",
    "        user_embs = node_embs[:self.num_users]\n",
    "        item_embs = node_embs[self.num_users:]\n",
    "        \n",
    "        batch_user_emb = user_embs[user_ids]\n",
    "        batch_pos_item_emb = item_embs[item_ids]\n",
    "        pos_scores = (batch_user_emb * batch_pos_item_emb).sum(dim=1)\n",
    "        \n",
    "        neg_item_ids = torch.randint(0, self.num_items, (len(user_ids),), device=self.device)\n",
    "        neg_scores = (batch_user_emb * item_embs[neg_item_ids]).sum(dim=1)\n",
    "        \n",
    "        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10).mean()\n",
    "        \n",
    "        recall, precision = 0.0, 0.0\n",
    "        if evaluate:\n",
    "             all_scores = torch.matmul(batch_user_emb, item_embs.T)\n",
    "             _, topk_indices = torch.topk(all_scores, k, dim=1)\n",
    "             hits = (topk_indices == item_ids.view(-1, 1)).any(dim=1).float()\n",
    "             recall = hits.mean()\n",
    "             precision = hits.mean() / k\n",
    "             \n",
    "        return loss, recall, precision\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Added weight_decay\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "aRuOnaapBK81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed months with < 100 interactions. Remaining months: 176\n",
      "Removed months with < 100 interactions. Remaining months: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type      | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------\n",
      "0 | node_emb | Embedding | 1.2 M  | train | 0    \n",
      "1 | tgcn     | TGCN      | 37.2 K | train | 0    \n",
      "2 | dropout  | Dropout   | 0      | train | 0    \n",
      "-------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.858     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 88/123 [00:56<00:22,  1.56it/s, v_num=11, train_loss=0.749, val_hit@10=0.000, val_recall@10=0.000, val_precision@10=0.000, val_ndcg@10=0.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file = 'data/book_interaction.csv'\n",
    "    # file = \"/content/drive/MyDrive/Computer Science Master/01 Luan Van/data/book_interaction.csv\"\n",
    "    data_module = DataModule(file)\n",
    "\n",
    "    data_module.prepare_data()\n",
    "\n",
    "    model = TGCNRecommender(\n",
    "        num_users=data_module.num_users,\n",
    "        num_items=data_module.num_items,\n",
    "        sequence_length = 6,\n",
    "        embedding_dim= 64,\n",
    "        lr = 0.001,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "    print(\"Completed\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqa2xQZFwDaTImHhVca8F7",
   "gpuType": "T4",
   "mount_file_id": "1xEeIB3zDaFVJwvNavB_5aFrzl6IqQUC5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
