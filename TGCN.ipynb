{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-5Jpgg49wzb",
    "outputId": "ec14c399-bd0d-4523-cdbc-4084ddfbfcfb"
   },
   "outputs": [],
   "source": [
    "# # 1. G·ª° b·ªè phi√™n b·∫£n qu√° m·ªõi hi·ªán t·∫°i\n",
    "# !pip uninstall torch torchvision torchaudio torch-scatter torch-sparse torch-geometric torch-geometric-temporal -y\n",
    "\n",
    "# # 2. C√†i ƒë·∫∑t PyTorch 2.5.1 (B·∫£n ·ªïn ƒë·ªãnh) + CUDA 12.4\n",
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# # 3. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán v·ªá tinh (Scatter/Sparse) d√†nh RI√äNG cho b·∫£n 2.5.1\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
    "\n",
    "# # 4. C√†i th∆∞ vi·ªán ch√≠nh\n",
    "# !pip install pytorch_lightning torch-geometric torch-geometric-temporal\n",
    "\n",
    "# # # 5. Runtime > Restart session\n",
    "# # # 6 Ignore this !pip section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 6172,
     "status": "error",
     "timestamp": 1768380494093,
     "user": {
      "displayName": "van hao truong",
      "userId": "08998182992862504611"
     },
     "user_tz": -420
    },
    "id": "xDk5XgSY3-_w",
    "outputId": "4b24502f-92da-42d7-8a99-05db6574f795"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN, EvolveGCNH\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAwareBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    K√≠ch ho·∫°t vi·ªác l·∫•y m·∫´u theo t·ª´ng b∆∞·ªõc th·ªùi gian (Time Step).\n",
    "    ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c m·∫´u trong m·ªôt batch ƒë·ªÅu thu·ªôc c√πng m·ªôt th·ªùi ƒëi·ªÉm 'time_idx'.\n",
    "    ƒêi·ªÅu n√†y c·ª±c k·ª≥ quan tr·ªçng cho T-GCN ƒë·ªÉ x·ª≠ l√Ω ƒë√∫ng c·ª≠a s·ªï ƒë·ªì th·ªã (edge_index_window).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source, batch_size, shuffle=True):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # data_source l√† TensorDataset(users, items, time_indices)\n",
    "        # Ch√∫ng ta c·∫ßn gom nh√≥m index thay theo time_idx\n",
    "        self.time_indices = data_source.tensors[2].numpy()\n",
    "        \n",
    "        # T·∫°o dictionary: time_idx -> list of dataset_indices\n",
    "        self.time_groups = defaultdict(list)\n",
    "        for idx, t in enumerate(self.time_indices):\n",
    "            self.time_groups[t].append(idx)\n",
    "            \n",
    "        self.time_keys = sorted(list(self.time_groups.keys()))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Lu√¥n gi·ªØ th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn ƒë·ªÉ m√¥ h√¨nh h·ªçc theo di·ªÖn ti·∫øn l·ªãch s·ª≠\n",
    "        # (Kh√¥ng shuffle keys n·ªØa)\n",
    "        keys = self.time_keys[:] \n",
    "            \n",
    "        for t in keys:\n",
    "            indices = self.time_groups[t][:]\n",
    "            \n",
    "            # Ch·ªâ x√°o tr·ªôn d·ªØ li·ªáu B√äN TRONG m·ªôt th√°ng\n",
    "            # ƒê·ªÉ c√°c batch trong c√πng 1 th√°ng c√≥ s·ª± ng·∫´u nhi√™n\n",
    "            if self.shuffle:\n",
    "                random.shuffle(indices)\n",
    "            \n",
    "            # T·∫°o c√°c batch t·ª´ indices c·ªßa th·ªùi ƒëi·ªÉm t\n",
    "            for i in range(0, len(indices), self.batch_size):\n",
    "                yield indices[i : i + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        # T·ªïng s·ªë batch\n",
    "        count = 0\n",
    "        for t in self.time_keys:\n",
    "            indices = self.time_groups[t]\n",
    "            count += (len(indices) + self.batch_size - 1) // self.batch_size\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, interaction_file, min_interactions= 100, batch_size=1024, train_size=0.7, val_size=0.15, test_size=0.15, built_dataset=None):\n",
    "        super().__init__()\n",
    "        self.interaction_file = interaction_file\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self.min_interactions = min_interactions\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # --- 1. Load & Preprocess ---\n",
    "        df = pd.read_csv(self.interaction_file)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "        df['month'] = df['timestamp'].dt.to_period('M')\n",
    "\n",
    "        # ƒê·∫øm s·ªë d√≤ng m·ªói th√°ng\n",
    "        month_counts = df['month'].value_counts()\n",
    "        valid_months = month_counts[month_counts >= self.min_interactions].index\n",
    "        \n",
    "        # Ch·ªâ gi·ªØ l·∫°i th√°ng h·ª£p l·ªá\n",
    "        df = df[df['month'].isin(valid_months)].copy()\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"D·ªØ li·ªáu sau khi l·ªçc b·ªã r·ªóng! H√£y gi·∫£m ng∆∞·ª°ng MIN_INTERACTIONS.\")\n",
    "            \n",
    "        print(f\"Removed months with < {self.min_interactions} interactions. Remaining months: {len(valid_months)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Mapping ID\n",
    "        unique_users = df['user_id'].unique()\n",
    "        unique_items = df['item_id'].unique()\n",
    "        \n",
    "        self.num_users = len(unique_users)\n",
    "        self.num_items = len(unique_items)\n",
    "        self.user_to_idx = {u: idx for idx, u in enumerate(unique_users)}\n",
    "        self.item_to_idx = {i: idx for idx, i in enumerate(unique_items)}\n",
    "\n",
    "        df['user_idx'] = df['user_id'].map(self.user_to_idx)\n",
    "        df['item_idx'] = df['item_id'].map(self.item_to_idx)\n",
    "\n",
    "        # T·∫°o Time Index (0, 1, 2, ...) cho c√°c th√°ng\n",
    "        valid_months_sorted = sorted(valid_months)\n",
    "\n",
    "        month_to_idx = {m: i for i, m in enumerate(valid_months_sorted)}\n",
    "        df['time_idx'] = df['month'].map(month_to_idx)\n",
    "        \n",
    "        self.num_time_steps = len(valid_months_sorted)\n",
    "\n",
    "        # --- 2. Temporal Split ---\n",
    "        train_end = int(self.num_time_steps * self.train_size)\n",
    "        val_end = train_end + int(self.num_time_steps * self.val_size)\n",
    "        \n",
    "        train_months = valid_months_sorted[:train_end]\n",
    "        val_months = valid_months_sorted[train_end:val_end]\n",
    "        test_months = valid_months_sorted[val_end:]\n",
    "        \n",
    "        # L·ªçc Time Index t∆∞∆°ng ·ª©ng\n",
    "        self.train_df = df[df['month'].isin(train_months)].sort_values('timestamp')\n",
    "        self.val_df = df[df['month'].isin(val_months)].sort_values('timestamp')\n",
    "        self.test_df = df[df['month'].isin(test_months)].sort_values('timestamp')\n",
    "\n",
    "        # print(self.train_df.head(1))\n",
    "        # user_id     item_id  timestamp  rating    month  user_idx  item_idx  time_idx  \n",
    "\n",
    "\n",
    "        # --- 3. Build Graph cho TO√ÄN B·ªò th·ªùi gian (ho·∫∑c √≠t nh·∫•t l√† Train) ---\n",
    "        # T-GCN c·∫ßn danh s√°ch c√°c edge_index theo th·ªùi gian\n",
    "        # Ta x√¢y d·ª±ng self.edge_index_all l√† list ƒë·ªô d√†i num_time_steps\n",
    "        self.edge_index_all = [None] * self.num_time_steps\n",
    "        \n",
    "        for month, group in df.groupby('month'):\n",
    "            t_idx = month_to_idx[month]\n",
    "            \n",
    "            src = torch.tensor(group['user_idx'].values, dtype=torch.long)\n",
    "            dst = torch.tensor(group['item_idx'].values, dtype=torch.long) + self.num_users\n",
    "            \n",
    "            # Undirected\n",
    "            edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n",
    "            self.edge_index_all[t_idx] = edge_index\n",
    "\n",
    "        # Fill c√°c th√°ng b·ªã thi·∫øu (n·∫øu c√≥) b·∫±ng edge_index r·ªóng ho·∫∑c c·ªßa th√°ng tr∆∞·ªõc\n",
    "        for t in range(self.num_time_steps):\n",
    "            if self.edge_index_all[t] is None:\n",
    "                # T·∫°o r·ªóng\n",
    "                self.edge_index_all[t] = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        # --- 4. User History ---\n",
    "        self.train_user_pos_items = self._build_user_history(self.train_df)\n",
    "        self.val_user_pos_items = self._build_user_history(self.val_df)\n",
    "        self.test_user_pos_items = self._build_user_history(self.test_df)\n",
    "\n",
    "    def _build_user_history(self, df_subset):\n",
    "        user_pos_items = defaultdict(set)\n",
    "        for u, i in zip(df_subset['user_idx'], df_subset['item_idx']):\n",
    "            user_pos_items[u].add(i)\n",
    "        return user_pos_items\n",
    "\n",
    "    def _create_dataset(self, df_subset):\n",
    "        if len(df_subset) == 0:\n",
    "            return TensorDataset(torch.empty(0), torch.empty(0), torch.empty(0))\n",
    "            \n",
    "        users = torch.tensor(df_subset['user_idx'].values, dtype=torch.long)\n",
    "        items = torch.tensor(df_subset['item_idx'].values, dtype=torch.long)\n",
    "        # TH√äM: Time Index\n",
    "        times = torch.tensor(df_subset['time_idx'].values, dtype=torch.long)\n",
    "        \n",
    "        return TensorDataset(users, items, times)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self._create_dataset(self.train_df)\n",
    "        # S·ª≠ d·ª•ng Custom Sampler ƒë·ªÉ ƒë·∫£m b·∫£o Batch ph√π h·ª£p v·ªõi Time-Step\n",
    "        # Batch tr·∫£ v·ªÅ s·∫Ω c√≥ d·∫°ng: (users, items, time_indices)\n",
    "        # Trong ƒë√≥ t·∫•t c·∫£ time_indices trong 1 batch ƒê·ªÄU GI·ªêNG NHAU (n·∫øu d√πng TimeAwareBatchSampler)\n",
    "       \n",
    "        batch_sampler = TimeAwareBatchSampler(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        return DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self._create_dataset(self.val_df)\n",
    "        # Val ƒë∆°n gi·∫£n c√≥ th·ªÉ d√πng default sampler\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self._create_dataset(self.test_df)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGCNRecommender(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, sequence_length, embedding_dim, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.processed = False # Flag ki·ªÉm tra setup\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.seq_len = sequence_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lr = lr\n",
    "\n",
    "        self.node_emb = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_emb.weight)\n",
    "        \n",
    "        self.tgcn = TGCN(in_channels=embedding_dim, out_channels=embedding_dim) \n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # L·∫•y tham chi·∫øu d·ªØ li·ªáu t·ª´ DataModule\n",
    "        if self.trainer.datamodule is not None:\n",
    "            self.edge_index_all = self.trainer.datamodule.edge_index_all\n",
    "            self.train_user_pos_items = self.trainer.datamodule.train_user_pos_items\n",
    "            self.processed = True\n",
    "\n",
    "    def forward(self, time_idx):\n",
    "        # Forward gi·ªù ƒë√¢y nh·∫≠n time_idx v√† ch·∫°y T-GCN tr√™n c·ª≠a s·ªï th·ªùi gian t∆∞∆°ng ·ª©ng\n",
    "        \n",
    "        # X√°c ƒë·ªãnh c·ª≠a s·ªï: [t - seq_len, t)\n",
    "        # N·∫øu time_idx < seq_len, ta l·∫•y t·ª´ 0 -> time_idx (ho·∫∑c pad)\n",
    "        start = max(0, time_idx - self.seq_len)\n",
    "        end = time_idx\n",
    "        \n",
    "        window_edges = self.edge_index_all[start : end + 1] # L·∫•y c·∫£ ƒë·ªì th·ªã hi·ªán t·∫°i ƒë·ªÉ t√≠ch h·ª£p th√¥ng tin\n",
    "        \n",
    "        x = self.node_emb.weight\n",
    "            \n",
    "        # Reset h m·ªói khi b·∫Øt ƒë·∫ßu m·ªôt chu·ªói m·ªõi? \n",
    "        # V·ªõi T-GCN training theo batch ng·∫´u nhi√™n v·ªÅ th·ªùi gian, ta th∆∞·ªùng ph·∫£i t√°i t·∫°o h t·ª´ ƒë·∫ßu c·ª≠a s·ªï.\n",
    "        # N·∫øu duy tr√¨ h li√™n t·ª•c (BPTT), ta c·∫ßn sampler tu·∫ßn t·ª± ch·∫∑t ch·∫Ω h∆°n.\n",
    "        # ·ªû ƒë√¢y ta gi·∫£ s·ª≠ t√°i t·∫°o local context:\n",
    "        h = torch.zeros(self.num_nodes, self.embedding_dim).to(x.device) # Reset local\n",
    "        \n",
    "        for edge_index in window_edges:\n",
    "            edge_index = edge_index.to(x.device)          \n",
    "            h = self.tgcn(X=x, edge_index=edge_index,H=h) # ph·∫£i ƒë·ªÉn X=x, H=h ƒë·ªÉ tr√°nh sai th·ª©c t·ª± trong h√†m forward\n",
    "\n",
    "        return h # (Num_nodes, Emb_dim)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_ids, item_ids, time_indices = batch\n",
    "        \n",
    "        # V√¨ d√πng TimeAwareBatchSampler, t·∫•t c·∫£ t trong batch l√† gi·ªëng nhau\n",
    "        current_t = time_indices[0].item()\n",
    "        \n",
    "        # Ch·∫°y model ƒë·ªÉ l·∫•y embedding t·∫°i th·ªùi ƒëi·ªÉm t\n",
    "        # Output shape: (Num_Nodes, Feature)\n",
    "        node_embs = self(current_t) \n",
    "        \n",
    "        user_embs = node_embs[:self.num_users]\n",
    "        item_embs = node_embs[self.num_users:]\n",
    "        \n",
    "        # T√≠nh Loss (Negative Sampling...)\n",
    "        batch_user_emb = user_embs[user_ids]\n",
    "        batch_pos_item_emb = item_embs[item_ids]\n",
    "        \n",
    "        pos_scores = torch.sum(batch_user_emb * batch_pos_item_emb, dim=1)\n",
    "        pos_loss = -torch.log(torch.sigmoid(pos_scores) + 1e-10).mean()\n",
    "        \n",
    "        # Negative Sampling ƒë∆°n gi·∫£n\n",
    "        neg_item_ids = torch.randint(0, self.num_items, (len(user_ids),), device=self.device)\n",
    "        batch_neg_item_emb = item_embs[neg_item_ids]\n",
    "        neg_scores = torch.sum(batch_user_emb * batch_neg_item_emb, dim=1)\n",
    "        neg_loss = -torch.log(1 - torch.sigmoid(neg_scores) + 1e-10).mean()\n",
    "        \n",
    "        loss = pos_loss + neg_loss\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "aRuOnaapBK81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed months with < 100 interactions. Remaining months: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type      | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------\n",
      "0 | node_emb | Embedding | 588 K  | train | 0    \n",
      "1 | tgcn     | TGCN      | 9.4 K  | train | 0    \n",
      "-------------------------------------------------------\n",
      "597 K     Trainable params\n",
      "0         Non-trainable params\n",
      "597 K     Total params\n",
      "2.392     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed months with < 100 interactions. Remaining months: 176\n",
      "Epoch 0:  22%|‚ñà‚ñà‚ñè       | 27/123 [09:46<34:45,  0.05it/s, v_num=48, train_loss=1.380] \n",
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.18it/s, v_num=50, train_loss=0.325]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:23<00:00,  5.17it/s, v_num=50, train_loss=0.325]\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file = 'data/book_interaction.csv'\n",
    "    # file = \"/content/drive/MyDrive/Computer Science Master/01 Luan Van/data/book_interaction.csv\"\n",
    "    data_module = DataModule(file)\n",
    "\n",
    "    data_module.prepare_data()\n",
    "\n",
    "    model = TGCNRecommender(\n",
    "        num_users=data_module.num_users,\n",
    "        num_items=data_module.num_items,\n",
    "        sequence_length = 5,\n",
    "        embedding_dim= 32,\n",
    "        lr = 0.001,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "    print(\"Completed\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqa2xQZFwDaTImHhVca8F7",
   "gpuType": "T4",
   "mount_file_id": "1xEeIB3zDaFVJwvNavB_5aFrzl6IqQUC5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
