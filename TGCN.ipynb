{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-5Jpgg49wzb",
    "outputId": "ec14c399-bd0d-4523-cdbc-4084ddfbfcfb"
   },
   "outputs": [],
   "source": [
    "# # 1. Gỡ bỏ phiên bản quá mới hiện tại\n",
    "# !pip uninstall torch torchvision torchaudio torch-scatter torch-sparse torch-geometric torch-geometric-temporal -y\n",
    "\n",
    "# # 2. Cài đặt PyTorch 2.5.1 (Bản ổn định) + CUDA 12.4\n",
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# # 3. Cài đặt các thư viện vệ tinh (Scatter/Sparse) dành RIÊNG cho bản 2.5.1\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
    "\n",
    "# # 4. Cài thư viện chính\n",
    "# !pip install pytorch_lightning torch-geometric torch-geometric-temporal\n",
    "\n",
    "# # # 5. Runtime > Restart session\n",
    "# # # 6 Ignore this !pip section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 6172,
     "status": "error",
     "timestamp": 1768380494093,
     "user": {
      "displayName": "van hao truong",
      "userId": "08998182992862504611"
     },
     "user_tz": -420
    },
    "id": "xDk5XgSY3-_w",
    "outputId": "4b24502f-92da-42d7-8a99-05db6574f795"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, interaction_file, batch_size=1024, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "        super().__init__()\n",
    "        self.interaction_file = interaction_file\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # --- 1. Load & Preprocess ---\n",
    "        df = pd.read_csv(self.interaction_file)\n",
    "        \n",
    "        # Chuyển timestamp\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df['month'] = df['timestamp'].dt.to_period('M')\n",
    "\n",
    "        # Mapping ID sang Index (0 -> N-1)\n",
    "        unique_users = df['user_id'].unique()\n",
    "        unique_items = df['item_id'].unique()\n",
    "        \n",
    "        self.num_users = len(unique_users)\n",
    "        self.num_items = len(unique_items)\n",
    "\n",
    "        self.user_to_idx = {u: idx for idx, u in enumerate(unique_users)}\n",
    "        self.item_to_idx = {i: idx for idx, i in enumerate(unique_items)}\n",
    "\n",
    "        # Áp dụng mapping vào DataFrame (Nhanh hơn iterrows rất nhiều)\n",
    "        df['user_idx'] = df['user_id'].map(self.user_to_idx)\n",
    "        df['item_idx'] = df['item_id'].map(self.item_to_idx)\n",
    "\n",
    "        # --- 2. Temporal Split ---\n",
    "        months = sorted(df['month'].unique())\n",
    "        n_months = len(months)\n",
    "        \n",
    "        train_end = int(n_months * self.train_size)\n",
    "        val_end = train_end + int(n_months * self.val_size)\n",
    "        \n",
    "        train_months = months[:train_end]\n",
    "        val_months = months[train_end:val_end]\n",
    "        test_months = months[val_end:]\n",
    "\n",
    "        # Tách DataFrame\n",
    "        self.train_df = df[df['month'].isin(train_months)]\n",
    "        self.val_df = df[df['month'].isin(val_months)]\n",
    "        self.test_df = df[df['month'].isin(test_months)]\n",
    "\n",
    "        print(f\"Split sizes -> Train: {len(self.train_df)}, Val: {len(self.val_df)}, Test: {len(self.test_df)}\")\n",
    "\n",
    "        # --- 3. Build Graph (Edge Index) cho Train Set ---\n",
    "        # Chỉ dùng dữ liệu Train để xây dựng đồ thị nền tảng\n",
    "        # Item nodes sẽ có ID từ num_users đến num_users + num_items - 1\n",
    "        src = torch.tensor(self.train_df['user_idx'].values, dtype=torch.long)\n",
    "        dst = torch.tensor(self.train_df['item_idx'].values, dtype=torch.long) + self.num_users\n",
    "        \n",
    "        # Tạo edge_index vô hướng (2 chiều: user->item và item->user)\n",
    "        self.edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n",
    "\n",
    "        # --- 4. Prepare User History (Cho việc sampling/evaluation nếu cần) ---\n",
    "        # Dùng set để tra cứu nhanh O(1)\n",
    "        self.train_user_pos_items = self._build_user_history(self.train_df)\n",
    "        self.val_user_pos_items = self._build_user_history(self.val_df)\n",
    "        self.test_user_pos_items = self._build_user_history(self.test_df)\n",
    "\n",
    "    def _build_user_history(self, df_subset):\n",
    "        \"\"\"Hàm phụ trợ để gom nhóm item theo user\"\"\"\n",
    "        user_pos_items = defaultdict(set)\n",
    "        # Zip nhanh hơn iterrows\n",
    "        for u, i in zip(df_subset['user_idx'], df_subset['item_idx']):\n",
    "            user_pos_items[u].add(i)\n",
    "        return user_pos_items\n",
    "\n",
    "    def _create_dataloader(self, df_subset, shuffle):\n",
    "        # Chuyển đổi thành TensorDataset để DataLoader hiểu\n",
    "        users = torch.tensor(df_subset['user_idx'].values, dtype=torch.long)\n",
    "        items = torch.tensor(df_subset['item_idx'].values, dtype=torch.long)\n",
    "        dataset = TensorDataset(users, items)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle, num_workers=2)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Shuffle=True cho Train set\n",
    "        return self._create_dataloader(self.train_df, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._create_dataloader(self.val_df, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._create_dataloader(self.test_df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-L86-kxBGia"
   },
   "outputs": [],
   "source": [
    "class TGCNRecommender(pl.LightningModule):\n",
    "    def __init__(self, num_cells, num_users, num_items, batch_size, embedding_dim, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_device = model_device\n",
    "\n",
    "        self.num_cells = num_cells\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = self.num_users + self.num_items\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Learnable Node Embeddings\n",
    "        self.node_emb = nn.Embedding(self.num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_emb.weight)\n",
    "\n",
    "        # T-GCN Layer\n",
    "        self.tgcns = nn.ModuleList([TGCN(in_channels=embedding_dim, \n",
    "                                        out_channels=embedding_dim) for _ in range(num_cells)])\n",
    "\n",
    "        self.lr = lr\n",
    "        self.h0 = None\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.edge_index = self.trainer.datamodule.edge_index.to(self.model_device)\n",
    "\n",
    "        self.train_user_pos_items = self.trainer.datamodule.train_user_pos_items\n",
    "        self.val_user_pos_items = self.trainer.datamodule.val_user_pos_items\n",
    "        self.test_user_pos_items = self.trainer.datamodule.test_user_pos_items\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.h0 = None\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        self.h0 = None\n",
    "\n",
    "    def forward(self):\n",
    "        # 1. Get current node embeddings\n",
    "        x = self.node_emb.weight\n",
    "\n",
    "        # 2. Update Embeddings with T-GCN\n",
    "        h_out = self.h0\n",
    "        for tgcn in self.tgcns:\n",
    "            h_out = tgcn(x, self.edge_index, h_out) #h_out shape: [num_nodes, embedding_dim]\n",
    "\n",
    "        user_embs = h_out[:self.num_users]\n",
    "        item_embs = h_out[self.num_users:]\n",
    "\n",
    "        return user_embs, item_embs\n",
    "\n",
    "    def compute_loss(self, batch, user_embs, item_embs):\n",
    "        user_ids, item_ids = batch\n",
    "        pos_item_ids = item_ids - self.hparams.num_users\n",
    "\n",
    "        # Get embeddings\n",
    "        user_emb = full_user_embs[user_ids]\n",
    "        pos_emb = full_item_embs[pos_item_ids]\n",
    "\n",
    "        # Compute positive scores\n",
    "        pos_scores = torch.exp(-torch.abs(user_emb - pos_emb).sum(dim=1))\n",
    "\n",
    "        ####################### Hard negative Sampling #######################\n",
    "        distances = torch.cdist(user_emb, full_item_embs, p=1)\n",
    "        scores = torch.exp(-distances)\n",
    "\n",
    "        ######## Mask all pos_item_ids of the user in train_dataset ########\n",
    "        ### Basically, the  model should only see the information in the train_dataset.\n",
    "        ### Therefore, only mask the pos_item_ids of the user in train_dataset\n",
    "        ### All cell (user, item) in val_dataset should be treated as blank hence don't mask the val_dataset\n",
    "\n",
    "        for i, u in enumerate(user_ids.tolist()):\n",
    "            pos_item_ids = [item - self.num_users for item in self.train_user_pos_items[u]]\n",
    "            scores[i, pos_item_ids] = float('-inf')\n",
    "        ######## Mask all pos_item_ids of the user in train_dataset ########\n",
    "\n",
    "        k = 10 # Select top-K most negatives for each user\n",
    "        neg_item_ids = torch.topk(scores, k=k, dim=1).indices\n",
    "\n",
    "        # Get embeddings for these negatives\n",
    "        neg_emb = full_item_embs[neg_item_ids]\n",
    "\n",
    "        neg_scores = torch.exp(-torch.abs(user_emb.unsqueeze(1) - neg_emb).sum(dim=2))\n",
    "        neg_scores = neg_scores.mean(dim=1)\n",
    "        ####################### Hard negative Sampling #######################\n",
    "\n",
    "\n",
    "        ####################### Compute Loss #######################\n",
    "        scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "        labels = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)], dim=0)\n",
    "\n",
    "        loss = F.binary_cross_entropy(scores, labels)\n",
    "        ####################### Compute Loss #######################\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_embs, item_embs = self()\n",
    "        loss = self.compute_loss(batch, user_embs, item_embs)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRuOnaapBK81"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_module = DataModule('data/book_interaction.csv')\n",
    "    data_module.prepare_data()\n",
    "\n",
    "    model = TGCNRecommender(\n",
    "        num_cells = 3,\n",
    "        num_users=data_module.num_users,\n",
    "        num_items=data_module.num_items,\n",
    "        batch_size = 1024,\n",
    "        embedding_dim= 64,\n",
    "        lr = 0.001,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqa2xQZFwDaTImHhVca8F7",
   "gpuType": "T4",
   "mount_file_id": "1xEeIB3zDaFVJwvNavB_5aFrzl6IqQUC5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
